{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Moodify",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pOO7CK9bAb-",
        "outputId": "00c168d4-92e5-48e6-d9c1-ffa35c9eb16c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJBni1IAbPEU",
        "outputId": "aa1cb938-d111-4c0f-9499-48ca5f78c473"
      },
      "source": [
        "!pip install mtcnn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mtcnn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/43/abee91792797c609c1bf30f1112117f7a87a713ebaa6ec5201d5555a73ef/mtcnn-0.1.0-py3-none-any.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 4.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn) (2.4.3)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn) (4.1.2.30)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.0->mtcnn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.0->mtcnn) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.0->mtcnn) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.0->mtcnn) (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->keras>=2.0.0->mtcnn) (1.15.0)\n",
            "Installing collected packages: mtcnn\n",
            "Successfully installed mtcnn-0.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0ba02tNv_Nt"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.patches import Rectangle\n",
        "from matplotlib.patches import Circle\n",
        "from PIL import Image \n",
        "from numpy import savez_compressed\n",
        "from numpy import asarray\n",
        "from os import listdir\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "\n",
        "def extract_face(image):\n",
        "  img1 = Image.open(image)            \n",
        "  img1 = img1.convert('RGB')         \n",
        "  pixels = asarray(img1)              \n",
        "  detector = MTCNN()                 \n",
        "  f = detector.detect_faces(pixels)\n",
        "  x1,y1,w,h = f[0]['box']             \n",
        "  x1, y1 = abs(x1), abs(y1)\n",
        "  x2 = abs(x1+w)\n",
        "  y2 = abs(y1+h)\n",
        "  store_face = pixels[y1:y2,x1:x2]\n",
        "  plt.imshow(store_face)\n",
        "  image1 = Image.fromarray(store_face,'RGB')   \n",
        "  image1 = image1.resize((160,160))             \n",
        "  face_array = asarray(image1)                  \n",
        "  return face_array\n",
        "\n",
        "\n",
        "def load_faces(directory):\n",
        "  face = []\n",
        "  i=1\n",
        "  for filename in listdir(directory):\n",
        "    path = directory + filename\n",
        "    faces = extract_face(path)\n",
        "    face.append(faces)\n",
        "  return face\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItbYSymHUYk0"
      },
      "source": [
        "def load_dataset(directory):\n",
        "  x, y = [],[]\n",
        "  i=1\n",
        "  for subdir in listdir(directory):\n",
        "    path = directory + subdir + '/'\n",
        "    faces = load_faces(path)\n",
        "    labels = [subdir for _ in range(len(faces))]\n",
        "    print(\"%d There are %d images in the class %s:\"%(i,len(faces),subdir))\n",
        "    x.extend(faces)\n",
        "    y.extend(labels)\n",
        "    i=i+1\n",
        "  return asarray(x),asarray(y)  \n",
        "\n",
        "\n",
        "trainX,trainY = load_dataset('/content/drive/MyDrive/Indian-celebrities/')\n",
        "print(trainX.shape,trainY.shape)\n",
        "savez_compressed('/content/drive/MyDrive/PROJECTS/face recog + mood/Indian-celeb-dataset.npz',trainX,trainY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Zdi3aQAawps"
      },
      "source": [
        "## Facenet Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "am5YxXXL6LMw"
      },
      "source": [
        "import numpy as np\n",
        "from numpy import savez_compressed\n",
        "from keras.models import load_model \n",
        "\n",
        "def extract_embeddings(model,face_pixels):\n",
        "  face_pixels = face_pixels.astype('float32')  \n",
        "  mean = face_pixels.mean()                   \n",
        "  std  = face_pixels.std()                    \n",
        "  face_pixels = (face_pixels - mean)/std       \n",
        "  samples = np.expand_dims(face_pixels,axis=0)    \n",
        "  yhat = model.predict(samples)\n",
        "  return yhat[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNJVTRzPbBcM",
        "outputId": "458a09ff-ecbd-4a9d-952f-b1e327b59c66"
      },
      "source": [
        "data = np.load('/content/drive/MyDrive/PROJECTS/face recog + mood/Indian-celeb-dataset.npz')\n",
        "trainx, trainy = data['arr_0'],data['arr_1']\n",
        "print(trainx.shape, trainy.shape)\n",
        "\n",
        "model = load_model('/content/drive/MyDrive/PROJECTS/face recog + mood/facenet_keras.h5')\n",
        "\n",
        "#get the face embeddings\n",
        "new_trainx = list()\n",
        "for train_pixels in trainx:\n",
        "  embeddings = extract_embeddings(model,train_pixels)\n",
        "  new_trainx.append(embeddings)\n",
        "new_trainx = np.asarray(new_trainx)            \n",
        "print(new_trainx.shape)\n",
        "\n",
        "#compress the 128 embeddings of each face \n",
        "savez_compressed('/content/drive/MyDrive/PROJECTS/face recog + mood/Indian-celeb-embeddings.npz',new_trainx,trainy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1538, 160, 160, 3) (1538,)\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "(1538, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZ6Pf8vljgkx"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "from numpy import asarray\n",
        "from numpy import array\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "from keras.models import load_model\n",
        "from numpy import expand_dims\n",
        "from numpy import reshape\n",
        "from numpy import load\n",
        "from numpy import max\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "Img = '/content/rajkummar.jpg'\n",
        "face = extract_face(Img)\n",
        "testx = face.reshape(-1,160,160,3)\n",
        "print(\"Input test data shape: \",testx.shape)\n",
        "\n",
        "#find embeddings\n",
        "model = load_model('/content/drive/MyDrive/PROJECTS/face recog + mood/facenet_keras.h5')\n",
        "new_testx = list()\n",
        "for test_pixels in testx:\n",
        "  embeddings = extract_embeddings(model,test_pixels)\n",
        "  new_testx.append(embeddings)\n",
        "new_testx = asarray(new_testx)  \n",
        "print(\"Input test embedding shape: \",new_testx.shape)\n",
        "\n",
        "data1 = load('/content/drive/MyDrive/PROJECTS/face recog + mood/Indian-celeb-dataset.npz')\n",
        "train_x,train_y = data1['arr_0'],data1['arr_1']\n",
        "\n",
        "data = load('/content/drive/MyDrive/PROJECTS/face recog + mood/Indian-celeb-embeddings.npz')\n",
        "trainx,trainy= data['arr_0'],data['arr_1']\n",
        "print(\"Loaded data: Train=%d , Test=%d\"%(trainx.shape[0],new_testx.shape[0]))\n",
        "\n",
        "#normalize the input \n",
        "in_encode = Normalizer(norm='l2')\n",
        "trainx = in_encode.transform(trainx)\n",
        "new_testx = in_encode.transform(new_testx)\n",
        "\n",
        "#create label vector\n",
        "out_encode = LabelEncoder()\n",
        "out_encode.fit(trainy)\n",
        "trainy = out_encode.transform(trainy)\n",
        "\n",
        "#svm classifier model \n",
        "model =SVC(kernel='linear', probability=True)\n",
        "model.fit(trainx,trainy)\n",
        "\n",
        "#predict\n",
        "predict_train = model.predict(trainx)\n",
        "predict_test = model.predict(new_testx)\n",
        "\n",
        "#Accuracy\n",
        "acc_train = accuracy_score(trainy,predict_train)\n",
        "\n",
        "#display\n",
        "trainy_list = list(trainy)\n",
        "p=int(predict_test)\n",
        "if p in trainy_list:\n",
        "  val = trainy_list.index(p)\n",
        "#display Input Image\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(face)\n",
        "predict_test = out_encode.inverse_transform(predict_test)\n",
        "plt.title(predict_test)\n",
        "plt.xlabel(\"Input Image\")\n",
        "#display Predicated data\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(train_x[val])\n",
        "trainy = out_encode.inverse_transform(trainy)\n",
        "plt.title(trainy[val])\n",
        "plt.xlabel(\"Predicted Data\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_p94BtganmON",
        "outputId": "804d6ece-d402-4a70-8eb4-ad69b84d7fdf"
      },
      "source": [
        "print(acc_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9986996098829649\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR2o_80hpnY8"
      },
      "source": [
        "import pickle\n",
        "pickle.dump(model, open('/content/drive/MyDrive/PROJECTS/face recog + mood/SVM.sav', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmn9dyVvp_9Q"
      },
      "source": [
        "## TESTING\n",
        "import pickle\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import Normalizer\n",
        "loaded_model = pickle.load(open('/content/drive/MyDrive/PROJECTS/face recog + mood/SVM.sav', 'rb'))\n",
        "facenet=load_model('/content/drive/MyDrive/PROJECTS/face recog + mood/facenet_keras.h5')\n",
        "Img = '/content/rajkummar.jpg'\n",
        "face = extract_face(Img)\n",
        "testx = face.reshape(-1,160,160,3)\n",
        "new_testx = list()\n",
        "for test_pixels in testx:\n",
        "  embeddings = extract_embeddings(facenet,test_pixels)\n",
        "  new_testx.append(embeddings)\n",
        "new_testx = asarray(new_testx)\n",
        "\n",
        "#ref data for label encoding\n",
        "data = np.load('/content/drive/MyDrive/PROJECTS/face recog + mood/Indian-celeb-embeddings.npz')\n",
        "trainx,trainy= data['arr_0'],data['arr_1']\n",
        "out_encode = LabelEncoder()\n",
        "out_encode.fit(trainy)\n",
        "\n",
        "in_encode = Normalizer(norm='l2')\n",
        "new_testx = in_encode.transform(new_testx)\n",
        "predict_test = loaded_model.predict(new_testx)\n",
        "\n",
        "plt.imshow(face)\n",
        "predict_test = out_encode.inverse_transform(predict_test)\n",
        "plt.title(predict_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHaFaVHno-3F"
      },
      "source": [
        "## Mood Predictor "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQzpTJ2Wozqm"
      },
      "source": [
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout,Activation,Flatten,BatchNormalization\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "import os\n",
        "\n",
        "num_classes=5\n",
        "img_rows,img_cols=48,48\n",
        "batch_size=128\n",
        "\n",
        "train_data_dir='/content/drive/MyDrive/PROJECTS/face recog + mood/fer2013/train'\n",
        "validation_data_dir='/content/drive/MyDrive/PROJECTS/face recog + mood/fer2013/validation'\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    shear_range=0.3,\n",
        "    zoom_range=0.3,\n",
        "    width_shift_range=0.4,\n",
        "    height_shift_range=0.4,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuDgIbr9E-sh"
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "                        train_data_dir,\n",
        "                        color_mode='grayscale',\n",
        "                        target_size=(img_rows,img_cols),\n",
        "                        batch_size=batch_size,\n",
        "                        class_mode='categorical',\n",
        "                        shuffle=True)\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "                                validation_data_dir,\n",
        "                                color_mode='grayscale',\n",
        "                                target_size=(img_rows,img_cols),\n",
        "                                batch_size=batch_size,\n",
        "                                class_mode='categorical',\n",
        "                                shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrZd4hQKMZnA"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(img_rows,img_cols,1)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(img_rows,img_cols,1)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(64,(3,3),padding='same',kernel_initializer='he_normal'))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64,(3,3),padding='same',kernel_initializer='he_normal'))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal'))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal'))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64,kernel_initializer='he_normal'))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64,kernel_initializer='he_normal'))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes,kernel_initializer='he_normal'))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9YrhEpmLlq5"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnP9tgxAIF1W"
      },
      "source": [
        "from keras.optimizers import RMSprop,SGD,Adam\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "checkpoint = ModelCheckpoint('/content/drive/MyDrive/PROJECTS/face recog + mood/EmotionDetectionModel.h5',\n",
        "                             monitor='val_loss',\n",
        "                             mode='min',\n",
        "                             save_best_only=True,\n",
        "                             verbose=1)\n",
        "\n",
        "earlystop = EarlyStopping(monitor='val_loss',\n",
        "                          min_delta=0,\n",
        "                          patience=3,\n",
        "                          verbose=1,\n",
        "                          restore_best_weights=True\n",
        "                          )\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
        "                              factor=0.2,\n",
        "                              patience=3,\n",
        "                              verbose=1,\n",
        "                              min_delta=0.0001)\n",
        "\n",
        "callbacks = [earlystop,checkpoint,reduce_lr]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppvwgVAOJFj5"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer = Adam(lr=0.001),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "epochs=25\n",
        "\n",
        "history=model.fit_generator(\n",
        "                train_generator,\n",
        "                epochs=epochs,\n",
        "                callbacks=callbacks,\n",
        "                validation_data=validation_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRILxRiMKprE"
      },
      "source": [
        "#TESTING\n",
        "from keras.models import load_model\n",
        "import pickle\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import Normalizer\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)   #warnings are irritating, sorry :P\n",
        "class_labels=['Angry','Happy','Neutral','Sad','Surprise']\n",
        "\n",
        "emotdet=load_model('/content/drive/MyDrive/PROJECTS/face recog + mood/EmotionDetectionModelV2.h5')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLFGip_TjFf8",
        "outputId": "348ba628-14ba-4e90-c7e9-349c73191a4d"
      },
      "source": [
        "!pip install curtsies"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting curtsies\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/17/9647eb1c537734adba77bd4613a2a6563a1439444827323cfe37652f9822/curtsies-0.3.5.tar.gz (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 3.1MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cwcwidth\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/d2/932e3933e54f3a9e5da369dceef236087e26c7f05c122d4ded24eef112fe/cwcwidth-0.1.4-cp37-cp37m-manylinux2010_x86_64.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.2MB/s \n",
            "\u001b[?25hCollecting blessings>=1.5\n",
            "  Downloading https://files.pythonhosted.org/packages/03/74/489f85a78247609c6b4f13733cbf3ba0d864b11aa565617b645d6fdf2a4a/blessings-1.7-py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from blessings>=1.5->curtsies) (1.15.0)\n",
            "Building wheels for collected packages: curtsies\n",
            "  Building wheel for curtsies (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for curtsies: filename=curtsies-0.3.5-cp37-none-any.whl size=35190 sha256=41652e654f1c3888efb9e2254f23cf78f63ee606c9c41e3723c2f842132f781f\n",
            "  Stored in directory: /root/.cache/pip/wheels/8c/ac/0e/498441cf5c927eb00d2ace1a839f1f6240494b705c9df92966\n",
            "Successfully built curtsies\n",
            "Installing collected packages: cwcwidth, blessings, curtsies\n",
            "Successfully installed blessings-1.7 curtsies-0.3.5 cwcwidth-0.1.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CItY5cGpRsF0"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "from curtsies.fmtfuncs import red, green, yellow, blue, cyan\n",
        "for i in range(1,9):\n",
        "  Img = f'/content/{i}.jpg'\n",
        "  face = extract_face(Img)\n",
        "  face=cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
        "  face=cv2.resize(face, (48,48), interpolation = cv2.INTER_AREA)\n",
        "  cv2_imshow(face)\n",
        "  face=face.astype('float')/255.0\n",
        "  face=img_to_array(face)\n",
        "  face=np.expand_dims(face,axis=0)\n",
        "  preds=emotdet.predict(face)\n",
        "  plt.imshow(Image.open(Img))\n",
        "  pred=preds[0]\n",
        "  print(cyan(class_labels[pred.argmax()]))\n",
        "  print('##################################################################################')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRB-NIw-j82p"
      },
      "source": [
        "# Music recommender\n",
        "\n",
        "Due to high amount of correlation of features. Only two major emotions come up for song recommendations which are happiness and saddness."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zs8P3yN_L0bq",
        "outputId": "0a5ff282-42fa-4450-e668-009450afc8eb"
      },
      "source": [
        "!pip install lightgbm"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.7/dist-packages (2.2.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from lightgbm) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightgbm) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjpM_zqe5l_d"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "data=pd.read_csv('/content/drive/MyDrive/PROJECTS/face recog + mood/data_spotifyV2.csv')\n",
        "data.drop_duplicates(inplace=True,subset=['name'])\n",
        "name=data['name']\n",
        "col_features = ['danceability', 'energy', 'valence', 'loudness']\n",
        "X = MinMaxScaler().fit_transform(data[col_features])\n",
        "kmeans = KMeans(init=\"k-means++\",\n",
        "                n_clusters=2,\n",
        "                random_state=15).fit(X)\n",
        "data['kmeans'] = kmeans.labels_\n",
        "data['song_name']=name\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjRWaWKXV296"
      },
      "source": [
        "og_data=data.copy()"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IL_XqStINvwH",
        "outputId": "f44eb4c2-369c-4bd6-de99-ee3ec2c77540"
      },
      "source": [
        "cluster=data.groupby(by=data['kmeans'])\n",
        "y=data.pop('kmeans')\n",
        "x=data.drop(columns=['name','artists','id','release_date','song_name','id_artists'])\n",
        "\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25)\n",
        "model=LGBMClassifier().fit(x_train,y_train)\n",
        "model.score(x_train,y_train)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.998106648828153"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOLfA0mBLRgk",
        "outputId": "7a5a9c50-5ffa-4469-bb53-513d236d9521"
      },
      "source": [
        "model.score(x_test,y_test)\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9964253397719026"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yu2sCA88MD6H"
      },
      "source": [
        "df=cluster.apply(lambda x: x.sort_values([\"popularity\"],ascending=False))\n",
        "df.reset_index(level=0, inplace=True)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yp_JeE-MH_B"
      },
      "source": [
        "EMOTIONS = [\"happy\",\"sad\"]\n",
        "  \n",
        "def get_results(emotion_code, NUM_RECOMMEND=10):\n",
        "  happy_set=[]\n",
        "  sad_set=[]\n",
        "  if emotion_code==0:\n",
        "      happy_set.append(df[df['kmeans']==0]['song_name'].head(NUM_RECOMMEND))\n",
        "      return pd.DataFrame(happy_set).T\n",
        "  else:\n",
        "      sad_set.append(df[df['kmeans']==1]['song_name'].head(NUM_RECOMMEND))\n",
        "      return pd.DataFrame(sad_set).T"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DSqXHkrN1r0",
        "outputId": "e2a4a3a5-e01b-4a04-c06e-0fad3dc11856"
      },
      "source": [
        "emotion_word=input(\"Enter your emotion (sad/happy): \").lower()\n",
        "NUM_RECOMMEND=int(input(\"Enter number of recommendations: \"))\n",
        "if emotion_word=='sad':\n",
        "    emotion_code=1\n",
        "else:\n",
        "    emotion_code=0\n",
        "results= get_results(emotion_code,NUM_RECOMMEND)\n",
        "print(results)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter your emotion (sad/happy): happy\n",
            "Enter number of recommendations: 20\n",
            "                                               song_name\n",
            "93802             Peaches (feat. Daniel Caesar & Giveon)\n",
            "93804                             Astronaut In The Ocean\n",
            "92811                                          telepatía\n",
            "92810                                    Save Your Tears\n",
            "93805                                Leave The Door Open\n",
            "93807  Friday (feat. Mufasa & Hypeman) - Dopamine Re-...\n",
            "93806                                               Fiel\n",
            "92821                                 LA NOCHE DE ANOCHE\n",
            "92826                                          positions\n",
            "93809                                                 Up\n",
            "93810                                 Goosebumps - Remix\n",
            "93812  Wellerman - Sea Shanty / 220 KID x Billen Ted ...\n",
            "92827                                       Hecha Pa' Mi\n",
            "92829                    Paradise (feat. Dermot Kennedy)\n",
            "91867                                   Watermelon Sugar\n",
            "93808                            Ella No Es Tuya - Remix\n",
            "93816                                         We're Good\n",
            "93814                                    Your Love (9PM)\n",
            "92841                            What You Know Bout Love\n",
            "92839                          Head & Heart (feat. MNEK)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ly4MP7WST7j8"
      },
      "source": [
        "## To add songs directly to spotify playlist"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyp3Upz2WqfF",
        "outputId": "a4b1468d-5bd9-441f-c053-dfc6c3fafe9e"
      },
      "source": [
        "ids=[]\n",
        "for x in np.asarray(results):\n",
        "  print(x)\n",
        "  ids.append(og_data[og_data['name']==x[0]]['id'])\n",
        "# ids=np.asarray(ids)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Peaches (feat. Daniel Caesar & Giveon)']\n",
            "['Astronaut In The Ocean']\n",
            "['telepatía']\n",
            "['Save Your Tears']\n",
            "['Leave The Door Open']\n",
            "['Friday (feat. Mufasa & Hypeman) - Dopamine Re-Edit']\n",
            "['Fiel']\n",
            "['LA NOCHE DE ANOCHE']\n",
            "['positions']\n",
            "['Up']\n",
            "['Goosebumps - Remix']\n",
            "['Wellerman - Sea Shanty / 220 KID x Billen Ted Remix']\n",
            "[\"Hecha Pa' Mi\"]\n",
            "['Paradise (feat. Dermot Kennedy)']\n",
            "['Watermelon Sugar']\n",
            "['Ella No Es Tuya - Remix']\n",
            "[\"We're Good\"]\n",
            "['Your Love (9PM)']\n",
            "['What You Know Bout Love']\n",
            "['Head & Heart (feat. MNEK)']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mD8RLcXEWPel",
        "outputId": "8e7d0c72-ba33-4408-f103-13b50580d0a8"
      },
      "source": [
        "ids=np.asarray(ids)\n",
        "ids=ids.ravel()\n",
        "print(ids)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['4iJyoBOLtHqaGxP12qzhQI' '3Ofmpyhv5UAQ70mENzB277'\n",
            " '6tDDoYIxWvMLTdKpjFkc1B' '5QO79kh1waicV47BqGRL3g'\n",
            " '7MAibcTli4IisCtbHKrGMh' '4cG7HUWYHBV6R6tHn1gxrl'\n",
            " '7Bk0uXKk1uPT0XuQbpFzvs' '2XIc1pqjXV3Cr2BQUGNBck'\n",
            " '35mvY5S1H3J2QZyna3TFe0' '1XXimziG1uhM0eDNCZCrUl'\n",
            " '5uEYRdEIh9Bo4fpjDd4Na9' '3iw6V4LH7yPj1ESORX9RIN'\n",
            " '3VvA1wSxukMLsvXoXtlwWx' '6ft4hAq6yde8jPZY2i5zLr'\n",
            " '6UelLqGlWMcVH1E5c4H7lY' '5YYW3yRktprLRr47WK219Y'\n",
            " '1diS6nkxMQc3wwC4G1j0bh' '5YaskwnGDZFDRipaqzbwQx'\n",
            " '1tkg4EHVoqnhR6iFEXb60y' '6cx06DFPPHchuUAcTxznu9']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qm0ISIYSlOW"
      },
      "source": [
        "from  helpers import *\n",
        "import spotipy\n",
        "from spotipy import SpotifyClientCredentials, util\n",
        "import pandas as pd\n",
        "\n",
        "client_id='your_client_id'\n",
        "client_secret='yout_client_secret'\n",
        "redirect_uri='your_url_to_redirect'\n",
        "\n",
        "username = 'your_username_code'\n",
        "scope_playlist = 'playlist-modify-public'\n",
        "scope_user = 'user-library-modify'\n",
        "scope_playing = 'user-read-currently-playing'\n",
        "\n",
        "manager = SpotifyClientCredentials(client_id,client_secret)\n",
        "sp = spotipy.Spotify(client_credentials_manager=manager)\n",
        "\n",
        "#Credentiasl to access the Playlists Music\n",
        "token_playlist= util.prompt_for_user_token(username,scope_playlist,client_id,client_secret,redirect_uri) \n",
        "sp_playlist = spotipy.Spotify(auth=token_playlist)\n",
        "\n",
        "\n",
        "playlist = sp_playlist.user_playlist_create(username,\"personal playlist\")\n",
        "sp_playlist.user_playlist_add_tracks(username,playlist,ids)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}